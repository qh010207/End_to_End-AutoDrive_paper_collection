# End_to_End-AutoDrive_with_LLM_paper_collectiom

**Paper and codes**

**Personal Recommendation:**

Applications of Large Language Models for Robot,Navigation and Scene Understanding, MIT Libraries, 6.2023 [[paper]https://dspace.mit.edu/handle/1721.1/151450]

(Demonstrated potential of attaching LM to Robotics Navigation task, specifically a room classification task by throwing detected spaital information in the LM model.(from three perspective, zero-shot, baseline and finetune)
Problem: compute limit, model old

LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving, archive,10.2023, [[paper]https://arxiv.org/abs/2310.03026]

A great template of paper writing in this field, the paper used the traditional pipeline, where input information from previous into chatgpt4 to make decision and straight input
Problem: no code.

DRIVEGPT4: INTERPRETABLE END-TO-END AUTONOMOUS DRIVING VIA LARGE LANGUAGE MODEL archive, 10.2023 [[paper]https://arxiv.org/abs/2310.01412]

The most important aspect, used multi-LLM aproach, image+video+text. retrained LLama multi-model to generate video-text parameters. then used end-to-end approch to fine- tune the system



Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles, archive, 9.2023 [[paper]https://arxiv.org/pdf/2307.07162.pdf]
Drive Like a Human: Rethinking Autonomous Driving with Large Language Models, archive, 7.2023 [[paper]https://arxiv.org/abs/2307.07162]
L3MVN: Leveraging Large Language Models for Visual Target Navigation, archive, 4.2023 [[paper]https://arxiv.org/abs/2304.05501] 

Into language model Semantic Maps, throw environment and vehicle information into Large language model, let the model decide.

Retentive Network: A Successor to Transformer for Large Language Models, archive, 8.2023 [[paper]https://arxiv.org/abs/2307.08621]

I did not get why the model was successful without softmax or any activation function.




**survey papers**
